#!/usr/bin/env python3
"""
å¯¼å‡ºé¡µé¢ DOM å’Œæˆªå›¾ï¼Œä¾›æœ¬åœ°åˆ†æ / è°ƒè¯•é€‰æ‹©å™¨ã€‚
è¿è¡Œ: python test/test_export_page_dom.py  æˆ–  python -m test.test_export_page_dom
"""
import asyncio
import os
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

from config import Config, create_env_template
from scraper.browser import BrowserManager


async def export_page_dom():
    """å¯¼å‡ºé¡µé¢DOMå’Œæˆªå›¾ä¾›æœ¬åœ°åˆ†æ"""
    print("\n" + "=" * 60)
    print("å¯¼å‡ºé¡µé¢DOMå’Œæˆªå›¾")
    print("=" * 60 + "\n")

    # éªŒè¯é…ç½®
    if not Config.validate():
        print("âŒ é…ç½®éªŒè¯å¤±è´¥")
        create_env_template()
        return

    print("âœ… é…ç½®éªŒè¯é€šè¿‡\n")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = "debug"
    os.makedirs(output_dir, exist_ok=True)

    # åˆ›å»ºæµè§ˆå™¨ç®¡ç†å™¨
    browser = BrowserManager(
        headless=False,  # ä½¿ç”¨éæ— å¤´æ¨¡å¼ä¾¿äºæŸ¥çœ‹
        slow_mo=Config.SLOW_MO,
        storage_state_path=Config.STORAGE_STATE_PATH
    )

    try:
        # å¯åŠ¨æµè§ˆå™¨
        print("ğŸš€ æ­£åœ¨å¯åŠ¨æµè§ˆå™¨...")
        page = await browser.start()
        print("âœ… æµè§ˆå™¨å·²å¯åŠ¨\n")

        # è·å–æ‰€æœ‰éœ€è¦ç›‘æ§çš„é¡µé¢é…ç½®
        page_configs = Config.get_all_pages()

        if not page_configs:
            print("âŒ æ²¡æœ‰é…ç½®ä»»ä½•ç›‘æ§é¡µé¢")
            return

        # æ£€æŸ¥ç™»å½•çŠ¶æ€
        first_url = page_configs[0][0]
        print("ğŸ” æ­£åœ¨æ£€æŸ¥ç™»å½•çŠ¶æ€...")
        if not await browser.is_logged_in(first_url):
            print("âš ï¸  éœ€è¦ç™»å½•...")
            success = await browser.login(
                Config.WHOP_EMAIL,
                Config.WHOP_PASSWORD,
                Config.LOGIN_URL
            )

            if not success:
                print("âŒ ç™»å½•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å‡­æ®æ˜¯å¦æ­£ç¡®")
                return
            print("âœ… ç™»å½•æˆåŠŸ\n")
        else:
            print("âœ… å·²ç™»å½•\n")

        # å¯¼èˆªåˆ°é¡µé¢
        test_url, test_type, _ = page_configs[0]
        print(f"ğŸ“„ æ­£åœ¨è®¿é—®é¡µé¢: [{test_type.upper()}] {test_url}")

        if not await browser.navigate(test_url):
            print(f"âŒ æ— æ³•å¯¼èˆªåˆ°é¡µé¢: {test_url}")
            return

        print("âœ… é¡µé¢å¯¼èˆªæˆåŠŸ\n")

        # ç­‰å¾…é¡µé¢åˆå§‹åŠ è½½
        print("â³ ç­‰å¾…é¡µé¢åˆå§‹åŠ è½½...")
        await asyncio.sleep(3)

        # ç­‰å¾…ç”¨æˆ·ç¡®è®¤
        print("\n" + "=" * 60)
        print("âš ï¸  é‡è¦æç¤º")
        print("=" * 60)
        print("\næµè§ˆå™¨çª—å£å·²æ‰“å¼€ï¼Œè¯·åœ¨æµè§ˆå™¨ä¸­æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š")
        print("\n1. ğŸ“œ æ»šåŠ¨é¡µé¢åˆ°æœ€åº•éƒ¨ï¼ŒåŠ è½½æ‰€æœ‰å†å²æ¶ˆæ¯")
        print("2. â³ ç­‰å¾…æ‰€æœ‰æ¶ˆæ¯å®Œå…¨åŠ è½½")
        print("3. âœ… ç¡®è®¤é¡µé¢å†…å®¹å®Œæ•´")
        print("\nå®ŒæˆåæŒ‰ [å›è½¦] é”®ç»§ç»­å¯¼å‡º...\n")

        # ç­‰å¾…ç”¨æˆ·è¾“å…¥
        input()

        print("\nâœ… æ”¶åˆ°ç¡®è®¤ï¼Œå¼€å§‹å¯¼å‡º...\n")

        # ç”Ÿæˆæ—¶é—´æˆ³
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # 1. å¯¼å‡ºå®Œæ•´HTML
        html_file = f"{output_dir}/page_{timestamp}.html"
        print(f"ğŸ“ æ­£åœ¨å¯¼å‡ºHTMLåˆ°: {html_file}")
        html_content = await page.content()
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        print(f"âœ… HTMLå·²ä¿å­˜ ({len(html_content)} å­—ç¬¦)\n")

        # 2. æˆªå›¾
        screenshot_file = f"{output_dir}/page_{timestamp}.png"
        print(f"ğŸ“¸ æ­£åœ¨æˆªå›¾åˆ°: {screenshot_file}")
        await page.screenshot(path=screenshot_file, full_page=True)
        print(f"âœ… æˆªå›¾å·²ä¿å­˜\n")

        # 3. å¯¼å‡ºæ¶ˆæ¯ç»“æ„åˆ†æ
        analysis_file = f"{output_dir}/analysis_{timestamp}.txt"
        print(f"ğŸ” æ­£åœ¨åˆ†æé¡µé¢ç»“æ„...")

        # ä½¿ç”¨JavaScriptåˆ†æé¡µé¢ç»“æ„
        js_analysis = """
        () => {
            const analysis = {
                url: window.location.href,
                title: document.title,
                all_elements_count: document.querySelectorAll('*').length,

                // æŸ¥æ‰¾å¯èƒ½çš„æ¶ˆæ¯å®¹å™¨
                potential_message_containers: [],

                // æŸ¥æ‰¾å¯èƒ½çš„æ–‡æœ¬å†…å®¹
                text_elements: []
            };

            // å°è¯•å¤šç§å¯èƒ½çš„é€‰æ‹©å™¨
            const selectors = [
                '[class*="message"]',
                '[class*="Message"]',
                '[class*="post"]',
                '[class*="Post"]',
                '[class*="content"]',
                '[class*="Content"]',
                '[role="article"]',
                'article',
                '[data-message]',
                '[data-post]'
            ];

            for (const selector of selectors) {
                const elements = document.querySelectorAll(selector);
                if (elements.length > 0) {
                    const sample = elements[0];
                    analysis.potential_message_containers.push({
                        selector: selector,
                        count: elements.length,
                        sample_classes: sample.className,
                        sample_id: sample.id,
                        sample_attributes: Array.from(sample.attributes).map(a => `${a.name}="${a.value.substring(0, 50)}"`),
                        sample_text: sample.innerText.substring(0, 200),
                        sample_html: sample.outerHTML.substring(0, 500)
                    });
                }
            }

            // æŸ¥æ‰¾åŒ…å«ç‰¹å®šå…³é”®å­—çš„å…ƒç´ 
            const keywords = ['GILD', 'CALL', 'PUT', 'æ­¢æŸ', 'å‡º'];
            const walker = document.createTreeWalker(
                document.body,
                NodeFilter.SHOW_TEXT,
                null,
                false
            );

            let node;
            while (node = walker.nextNode()) {
                const text = node.textContent.trim();
                if (text.length > 10) {
                    for (const keyword of keywords) {
                        if (text.includes(keyword)) {
                            let element = node.parentElement;
                            let depth = 0;
                            const path = [];

                            while (element && depth < 5) {
                                path.push({
                                    tag: element.tagName,
                                    class: element.className,
                                    id: element.id
                                });
                                element = element.parentElement;
                                depth++;
                            }

                            analysis.text_elements.push({
                                text: text.substring(0, 100),
                                keyword: keyword,
                                path: path
                            });
                            break;
                        }
                    }
                }
            }

            return analysis;
        }
        """

        analysis_data = await page.evaluate(js_analysis)

        with open(analysis_file, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("é¡µé¢ç»“æ„åˆ†æ\n")
            f.write("=" * 60 + "\n\n")
            f.write(f"URL: {analysis_data['url']}\n")
            f.write(f"æ ‡é¢˜: {analysis_data['title']}\n")
            f.write(f"æ€»å…ƒç´ æ•°: {analysis_data['all_elements_count']}\n\n")

            f.write("=" * 60 + "\n")
            f.write("å¯èƒ½çš„æ¶ˆæ¯å®¹å™¨é€‰æ‹©å™¨\n")
            f.write("=" * 60 + "\n\n")

            for i, container in enumerate(analysis_data['potential_message_containers'], 1):
                f.write(f"{i}. é€‰æ‹©å™¨: {container['selector']}\n")
                f.write(f"   æ•°é‡: {container['count']}\n")
                f.write(f"   ç±»å: {container['sample_classes']}\n")
                f.write(f"   ID: {container['sample_id']}\n")
                f.write(f"   å±æ€§:\n")
                for attr in container['sample_attributes']:
                    f.write(f"      {attr}\n")
                f.write(f"\n   ç¤ºä¾‹æ–‡æœ¬:\n   {container['sample_text']}\n")
                f.write(f"\n   ç¤ºä¾‹HTML:\n   {container['sample_html']}\n")
                f.write("\n" + "-" * 60 + "\n\n")

            f.write("\n" + "=" * 60 + "\n")
            f.write("åŒ…å«äº¤æ˜“å…³é”®å­—çš„å…ƒç´ \n")
            f.write("=" * 60 + "\n\n")

            for i, elem in enumerate(analysis_data['text_elements'][:20], 1):
                f.write(f"{i}. å…³é”®å­—: {elem['keyword']}\n")
                f.write(f"   æ–‡æœ¬: {elem['text']}\n")
                f.write(f"   è·¯å¾„:\n")
                for j, node in enumerate(elem['path']):
                    indent = "   " * (j + 2)
                    f.write(f"{indent}<{node['tag']} class='{node['class']}' id='{node['id']}'>\n")
                f.write("\n")

        print(f"âœ… åˆ†æå·²ä¿å­˜\n")

        print("\n" + "=" * 60)
        print("å¯¼å‡ºå®Œæˆï¼")
        print("=" * 60)
        print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"   1. HTML: {html_file}")
        print(f"   2. æˆªå›¾: {screenshot_file}")
        print(f"   3. åˆ†æ: {analysis_file}")
        print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print(f"   1. æ‰“å¼€ {html_file} æŸ¥çœ‹é¡µé¢ç»“æ„")
        print(f"   2. æŸ¥çœ‹ {screenshot_file} å¯¹ç…§å®é™…æ˜¾ç¤º")
        print(f"   3. é˜…è¯» {analysis_file} äº†è§£å¯ç”¨çš„é€‰æ‹©å™¨")
        print(f"   4. æ ¹æ®åˆ†æç»“æœè°ƒæ•´ message_extractor.py ä¸­çš„é€‰æ‹©å™¨")
        print("=" * 60 + "\n")

    except Exception as e:
        print(f"\nâŒ å¯¼å‡ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

    finally:
        # å…³é—­æµè§ˆå™¨
        print("\nğŸ§¹ æ­£åœ¨æ¸…ç†èµ„æº...")
        await browser.close()
        print("âœ… æµè§ˆå™¨å·²å…³é—­")


if __name__ == "__main__":
    asyncio.run(export_page_dom())
