#!/usr/bin/env python3
"""
æœ¬åœ°HTMLæ¶ˆæ¯åˆ†æè„šæœ¬
ç›´æ¥åˆ†ææœ¬åœ°HTMLæ–‡ä»¶ï¼Œä½¿ç”¨EnhancedMessageExtractoræå–æ¶ˆæ¯å¹¶åˆ†ç»„
æ— éœ€å¯åŠ¨æµè§ˆå™¨è¿æ¥ç½‘é¡µ
"""
import asyncio
import os
import sys
import json
from glob import glob
from datetime import datetime
from playwright.async_api import async_playwright


def export_messages_to_json(raw_groups, html_file: str) -> str:
    """
    å¯¼å‡ºæ¶ˆæ¯åˆ°JSONæ–‡ä»¶
    
    Args:
        raw_groups: æ¶ˆæ¯ç»„åˆ—è¡¨
        html_file: æºHTMLæ–‡ä»¶è·¯å¾„
        
    Returns:
        å¯¼å‡ºçš„JSONæ–‡ä»¶è·¯å¾„
    """
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    base_name = os.path.splitext(os.path.basename(html_file))[0]
    output_dir = os.path.dirname(html_file) or 'debug'
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    json_file = os.path.join(output_dir, f"{base_name}_messages_{timestamp}.json")
    
    # è½¬æ¢ä¸ºç®€åŒ–æ ¼å¼
    messages_data = []
    for group in raw_groups:
        simple_dict = group.to_simple_dict()
        messages_data.append(simple_dict)
    
    # æ„å»ºå®Œæ•´çš„JSONæ•°æ®ç»“æ„
    output_data = {
        "metadata": {
            "source_file": html_file,
            "export_time": datetime.now().isoformat(),
            "total_messages": len(messages_data),
            "extractor_version": "3.9"
        },
        "messages": messages_data
    }
    
    # å†™å…¥JSONæ–‡ä»¶
    try:
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        return json_file
    except Exception as e:
        print(f"âŒ JSONå¯¼å‡ºå¤±è´¥: {e}")
        return None


async def analyze_html_messages(html_file: str, export_json: bool = True):
    """
    åˆ†ææœ¬åœ°HTMLæ–‡ä»¶ä¸­çš„æ¶ˆæ¯
    
    Args:
        html_file: HTMLæ–‡ä»¶è·¯å¾„
    """
    print("\n" + "=" * 80)
    print("æœ¬åœ°HTMLæ¶ˆæ¯æå–åˆ†æ")
    print("=" * 80 + "\n")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(html_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {html_file}")
        return
    
    print(f"ğŸ“„ æºæ–‡ä»¶: {html_file}")
    file_size = os.path.getsize(html_file) / 1024 / 1024
    print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:.2f} MB\n")
    
    # è¯»å–HTMLæ–‡ä»¶
    print("ğŸ“– æ­£åœ¨è¯»å–HTMLæ–‡ä»¶...")
    try:
        with open(html_file, 'r', encoding='utf-8') as f:
            html_content = f.read()
        print(f"âœ… å·²è¯»å– {len(html_content):,} å­—ç¬¦\n")
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return
    
    # ä½¿ç”¨playwrightåŠ è½½HTMLå¹¶æå–æ¶ˆæ¯
    print("ğŸš€ æ­£åœ¨å¯åŠ¨Playwright...")
    async with async_playwright() as p:
        try:
            # å¯åŠ¨æµè§ˆå™¨
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()
            
            print("âœ… Playwrightå·²å¯åŠ¨\n")
            
            # åŠ è½½HTMLå†…å®¹
            print("ğŸ“ æ­£åœ¨åŠ è½½HTMLå†…å®¹...")
            await page.set_content(html_content)
            print("âœ… HTMLå†…å®¹å·²åŠ è½½\n")
            
            # ä½¿ç”¨EnhancedMessageExtractoræå–æ¶ˆæ¯
            print("ğŸ” æ­£åœ¨æå–æ¶ˆæ¯...")
            from scraper.message_extractor import EnhancedMessageExtractor
            from scraper.message_grouper import MessageGrouper, format_as_table, format_as_detailed_table
            
            extractor = EnhancedMessageExtractor(page)
            raw_groups = await extractor.extract_message_groups()
            
            print(f"âœ… æˆåŠŸæå– {len(raw_groups)} æ¡åŸå§‹æ¶ˆæ¯\n")
            
            if not raw_groups:
                print("âš ï¸  æœªæå–åˆ°ä»»ä½•æ¶ˆæ¯")
                print("\nğŸ’¡ å¯èƒ½çš„åŸå› :")
                print("   1. HTMLæ–‡ä»¶ä¸å®Œæ•´")
                print("   2. é¡µé¢ç»“æ„å·²å˜åŒ–")
                print("   3. é€‰æ‹©å™¨éœ€è¦æ›´æ–°")
                await browser.close()
                return
            
            # å¯¼å‡ºJSONæ–‡ä»¶
            if export_json:
                print("ğŸ“¤ æ­£åœ¨å¯¼å‡ºJSONæ–‡ä»¶...")
                json_file = export_messages_to_json(raw_groups, html_file)
                if json_file:
                    file_size = os.path.getsize(json_file) / 1024
                    print(f"âœ… JSONæ–‡ä»¶å·²å¯¼å‡º: {json_file}")
                    print(f"   æ–‡ä»¶å¤§å°: {file_size:.2f} KB")
                    print(f"   æ¶ˆæ¯æ•°é‡: {len(raw_groups)}")
                    print()
            
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            messages = []
            for group in raw_groups:
                message_dict = {
                    'id': group.group_id,
                    'author': group.author,
                    'timestamp': group.timestamp,
                    'content': group.get_full_content(),
                    'primary_message': group.primary_message,
                    'related_messages': group.related_messages,
                    'quoted_message': group.quoted_message,
                    'quoted_context': group.quoted_context,
                    'has_message_above': group.has_message_above,
                    'has_message_below': group.has_message_below
                }
                messages.append(message_dict)
            
            # ä½¿ç”¨æ¶ˆæ¯åˆ†ç»„å™¨è¿›è¡Œäº¤æ˜“ç»„èšåˆï¼ˆæµå¼å¤„ç†ï¼‰
            print("ğŸ”„ æ­£åœ¨æŒ‰æ—¶é—´é¡ºåºæµå¼å¤„ç†æ¶ˆæ¯...\n")
            grouper = MessageGrouper()
            trade_groups = grouper.group_messages(messages, stream_output=True)
            
            # è§£ææ¶ˆæ¯å¹¶è½¬åŒ–ä¸ºbrokeræŒ‡ä»¤
            from parser.option_parser import OptionParser
            
            # æ£€æŸ¥æ˜¯å¦æ˜¾ç¤ºè§£æè¾“å‡ºï¼ˆå¯é€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶ï¼‰
            show_parser_output = os.getenv('SHOW_PARSER_OUTPUT', 'true').lower() in ('true', '1', 'yes')
            
            if show_parser_output:
                print("\n" + "="*140)
                print("ã€æŒ‡ä»¤è§£æ - è½¬åŒ–ä¸ºBrokerå¯ç”¨æŒ‡ä»¤ã€‘")
                print("="*140)
            
            # æŒ‰æ—¶é—´æ’åºæ‰€æœ‰æ¶ˆæ¯ï¼ˆä¸æµå¼å¤„ç†ä¿æŒä¸€è‡´ï¼‰
            from datetime import datetime
            def parse_ts(msg):
                ts = msg.get('timestamp', '')
                if not ts:
                    return datetime.max
                try:
                    return datetime.strptime(ts, '%b %d, %Y %I:%M %p')
                except:
                    return datetime.max
            sorted_messages = sorted(messages, key=lambda x: (parse_ts(x), x.get('id', '')))
            
            # ç»Ÿè®¡è§£æç»“æœ
            total_messages = 0
            parsed_success = 0
            parsed_failed = 0
            
            # æ”¶é›†è§£æç»“æœç”¨äºè¡¨æ ¼å±•ç¤º
            parse_results = []
            
            # é€æ¡è§£ææ¶ˆæ¯
            for msg in sorted_messages:
                content = msg.get('content', '').strip()
                timestamp = msg.get('timestamp', 'æœªçŸ¥')
                msg_id = msg.get('id', '')
                
                # è¿‡æ»¤çº¯å…ƒæ•°æ®æ¶ˆæ¯
                if not content or len(content) < 5:
                    continue
                
                total_messages += 1
                
                # æ¸…ç†æ¶ˆæ¯å†…å®¹ï¼šç§»é™¤å¼•ç”¨å‰ç¼€ã€ä½œè€…ä¿¡æ¯ã€æ—¶é—´æˆ³ç­‰å¹²æ‰°ä¿¡æ¯
                import re
                content_clean = content
                
                # 1. ç§»é™¤ [å¼•ç”¨] å‰ç¼€
                content_clean = re.sub(r'^\[å¼•ç”¨\]\s*', '', content_clean)
                
                # 2. ç§»é™¤å¼€å¤´çš„ä½œè€…å’Œæ—¶é—´ä¿¡æ¯ï¼ˆå¦‚ "xiaozhaoluckyâ€¢Jan 22, 2026 10:41 PM"ï¼‰
                content_clean = re.sub(r'^[\w]+â€¢[A-Z][a-z]{2,9}\s+\d{1,2},\s+\d{4}\s+\d{1,2}:\d{2}\s+[AP]M\s*', '', content_clean)
                
                # 3. ç§»é™¤å¼€å¤´çš„ X æ ‡è®°ï¼ˆå¼•ç”¨æ ‡è®°ï¼‰
                content_clean = re.sub(r'^[Xxï¼¸ï½˜]+', '', content_clean)
                
                # 4. å†æ¬¡æ¸…ç†ä½œè€…ä¿¡æ¯ï¼ˆå¤„ç† "Xxiaozhaoluckyâ€¢..." çš„æƒ…å†µï¼‰
                content_clean = re.sub(r'^[\w]+â€¢[A-Z][a-z]{2,9}\s+\d{1,2},\s+\d{4}\s+\d{1,2}:\d{2}\s+[AP]M\s*', '', content_clean)
                
                # 5. ç§»é™¤å¼€å¤´çš„æ—¶é—´æ ‡è®°ï¼ˆå¦‚ "â€¢Wednesday 11:04 PM"ï¼‰
                content_clean = re.sub(r'^â€¢?\s*[A-Z][a-z]+\s+\d{1,2}:\d{2}\s+[AP]M\s*', '', content_clean)
                
                # 6. ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
                content_clean = content_clean.strip()
                
                # å¦‚æœæ¸…ç†åå†…å®¹è¿‡çŸ­ï¼Œè·³è¿‡
                if not content_clean or len(content_clean) < 5:
                    continue
                
                # å°è¯•è§£æï¼ˆä½¿ç”¨æ¸…ç†åçš„å†…å®¹ï¼Œä¼ å…¥æ¶ˆæ¯æ—¶é—´æˆ³ç”¨äºè®¡ç®—ç›¸å¯¹æ—¥æœŸï¼‰
                instruction = OptionParser.parse(content_clean, message_id=msg_id, message_timestamp=timestamp)
                
                # æ”¶é›†ç»“æœ
                if instruction:
                    parsed_success += 1
                    ticker = instruction.ticker if instruction.ticker else "æœªè¯†åˆ«"
                    # ç§»é™¤æ¢è¡Œç¬¦å¹¶é™åˆ¶é•¿åº¦
                    raw_msg = content_clean.replace('\n', ' ').replace('\r', ' ')[:80]
                    parse_results.append({
                        'timestamp': timestamp,
                        'ticker': ticker,
                        'status': 'âœ…',
                        'type': instruction.instruction_type,
                        'instruction': instruction,  # ä¿å­˜å®Œæ•´çš„instructionå¯¹è±¡
                        'raw_message': raw_msg
                    })
                else:
                    parsed_failed += 1
                    from scraper.message_grouper import MessageGrouper
                    grouper = MessageGrouper()
                    ticker = grouper._extract_symbol(content_clean) or "æœªè¯†åˆ«"
                    # ç§»é™¤æ¢è¡Œç¬¦å¹¶é™åˆ¶é•¿åº¦
                    content_display = content_clean.replace('\n', ' ').replace('\r', ' ')[:80]
                    if len(content_clean) > 80:
                        content_display += "..."
                    parse_results.append({
                        'timestamp': timestamp,
                        'ticker': ticker,
                        'status': 'âŒ',
                        'type': 'FAILED',
                        'instruction': None,
                        'error': f"è§£æå¤±è´¥",
                        'raw_message': content_display
                    })
            
            # è¡¨æ ¼å±•ç¤º
            if show_parser_output and parse_results:
                from rich.console import Console
                from rich.table import Table
                from rich import box
                
                console = Console()
                print()
                
                # ä¸ºæ¯ä¸ªæŒ‡ä»¤åˆ›å»ºç‹¬ç«‹è¡¨æ ¼
                for idx, result in enumerate(parse_results, 1):
                    # æ„å»ºè¡¨æ ¼æ ‡é¢˜
                    if result['status'] == 'âœ…':
                        title = f"#{idx} {result['type']} - {result['ticker']}"
                        title_style = "bold green"
                    else:
                        title = f"#{idx} è§£æå¤±è´¥ - {result['ticker']}"
                        title_style = "bold red"
                    
                    # åˆ›å»ºè¡¨æ ¼
                    table = Table(
                        title=title,
                        title_style=title_style,
                        box=box.ROUNDED,
                        show_header=True,
                        header_style="bold cyan",
                        width=80,
                        padding=(0, 1)
                    )
                    
                    # æ·»åŠ åˆ—
                    table.add_column("å­—æ®µ", style="cyan", width=18, no_wrap=True)
                    table.add_column("å€¼", style="white", width=56, no_wrap=False)
                    
                    # æ·»åŠ åŸºæœ¬ä¿¡æ¯
                    table.add_row("æ—¶é—´", result['timestamp'])
                    table.add_row("æœŸæƒä»£ç ", result['ticker'])
                    table.add_row("æŒ‡ä»¤ç±»å‹", result['type'])
                    table.add_row("çŠ¶æ€", result['status'])
                    
                    # æ ¹æ®æŒ‡ä»¤ç±»å‹æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                    if result['status'] == 'âœ…' and result['instruction']:
                        inst = result['instruction']
                        
                        if result['type'] == 'BUY':
                            # ä¹°å…¥æŒ‡ä»¤
                            if inst.option_type:
                                table.add_row("æœŸæƒç±»å‹", inst.option_type)
                            if inst.strike:
                                table.add_row("è¡Œæƒä»·", f"${inst.strike}")
                            if inst.expiry:
                                table.add_row("åˆ°æœŸæ—¥", inst.expiry)
                            if inst.price_range:
                                table.add_row("ä»·æ ¼åŒºé—´", f"${inst.price_range[0]} - ${inst.price_range[1]}")
                                table.add_row("ä»·æ ¼(ä¸­é—´å€¼)", f"${inst.price}")
                            elif inst.price:
                                table.add_row("ä»·æ ¼", f"${inst.price}")
                            if inst.position_size:
                                table.add_row("ä»“ä½å¤§å°", inst.position_size)
                        
                        elif result['type'] == 'SELL':
                            # å–å‡ºæŒ‡ä»¤
                            if inst.price_range:
                                table.add_row("ä»·æ ¼åŒºé—´", f"${inst.price_range[0]} - ${inst.price_range[1]}")
                                table.add_row("ä»·æ ¼(ä¸­é—´å€¼)", f"${inst.price}")
                            elif inst.price:
                                table.add_row("ä»·æ ¼", f"${inst.price}")
                            if inst.sell_quantity:
                                table.add_row("å–å‡ºæ•°é‡", inst.sell_quantity)
                        
                        elif result['type'] == 'CLOSE':
                            # æ¸…ä»“æŒ‡ä»¤
                            if inst.price_range:
                                table.add_row("ä»·æ ¼åŒºé—´", f"${inst.price_range[0]} - ${inst.price_range[1]}")
                                table.add_row("ä»·æ ¼(ä¸­é—´å€¼)", f"${inst.price}")
                            elif inst.price:
                                table.add_row("ä»·æ ¼", f"${inst.price}")
                            table.add_row("æ•°é‡", "å…¨éƒ¨")
                        
                        elif result['type'] == 'MODIFY':
                            # ä¿®æ”¹æŒ‡ä»¤
                            if inst.stop_loss_range:
                                table.add_row("æ­¢æŸåŒºé—´", f"${inst.stop_loss_range[0]} - ${inst.stop_loss_range[1]}")
                                table.add_row("æ­¢æŸ(ä¸­é—´å€¼)", f"${inst.stop_loss_price}")
                            elif inst.stop_loss_price:
                                table.add_row("æ­¢æŸä»·æ ¼", f"${inst.stop_loss_price}")
                            
                            if inst.take_profit_range:
                                table.add_row("æ­¢ç›ˆåŒºé—´", f"${inst.take_profit_range[0]} - ${inst.take_profit_range[1]}")
                                table.add_row("æ­¢ç›ˆ(ä¸­é—´å€¼)", f"${inst.take_profit_price}")
                            elif inst.take_profit_price:
                                table.add_row("æ­¢ç›ˆä»·æ ¼", f"${inst.take_profit_price}")
                        
                        # æ˜¾ç¤ºåŸå§‹æ¶ˆæ¯
                        if result['raw_message']:
                            raw_msg = result['raw_message']
                            if len(raw_msg) > 75:
                                table.add_row("åŸå§‹æ¶ˆæ¯", raw_msg[:75] + "...")
                            else:
                                table.add_row("åŸå§‹æ¶ˆæ¯", raw_msg)
                    else:
                        # å¤±è´¥çš„è§£æ
                        if 'error' in result:
                            table.add_row("é”™è¯¯", result['error'])
                        raw_msg = result['raw_message']
                        if len(raw_msg) > 75:
                            table.add_row("åŸå§‹æ¶ˆæ¯", raw_msg[:75] + "...")
                        else:
                            table.add_row("åŸå§‹æ¶ˆæ¯", raw_msg)
                    
                    # æ¸²æŸ“è¡¨æ ¼
                    console.print(table)
                    print()
                
                # ç»Ÿè®¡ä¿¡æ¯
                stats_table = Table(
                    title="ğŸ“Š è§£æç»Ÿè®¡",
                    title_style="bold yellow",
                    box=box.DOUBLE,
                    show_header=False,
                    width=80
                )
                stats_table.add_column("", style="bold cyan")
                stats_table.add_row(f"æ€»æ¶ˆæ¯æ•°: {total_messages} | æˆåŠŸ: {parsed_success} | å¤±è´¥: {parsed_failed} | æˆåŠŸç‡: {parsed_success/total_messages*100:.1f}%")
                console.print(stats_table)
                print()
            
            # æ³¨æ„ï¼šæ¶ˆæ¯å·²åœ¨group_messagesä¸­æµå¼è¾“å‡ºï¼Œæ— éœ€å†è°ƒç”¨format_as_rich_panels
            
            # æ˜¾ç¤ºåŸå§‹æ¶ˆæ¯ï¼ˆå‰200æ¡ï¼‰- ä½¿ç”¨æ–°çš„ç®€åŒ–æ ¼å¼
            print("\n" + "=" * 80)
            print("ã€åŸå§‹æ¶ˆæ¯è¯¦æƒ…ã€‘ï¼ˆå‰200æ¡ - æ–°æ ¼å¼ï¼‰")
            print("=" * 80)
            
            import json
            for i, group in enumerate(raw_groups[:200], 1):
                # ä½¿ç”¨æ–°çš„ç®€åŒ–æ ¼å¼
                simple_data = group.to_simple_dict()
                
                print(f"\n{i}. æ¶ˆæ¯ #{i}")
                print("   " + "-" * 76)
                print(f"   domID:     {simple_data['domID']}")
                print(f"   position:  {simple_data['position']}")
                print(f"   timestamp: {simple_data['timestamp'] or '(æœªè¯†åˆ«)'}")
                print(f"   content:   {simple_data['content'][:70]}...")
                
                if simple_data['refer']:
                    print(f"   refer:     {simple_data['refer'][:70]}...")
                
                if simple_data['history']:
                    print(f"   history:   [{len(simple_data['history'])} æ¡å†å²æ¶ˆæ¯]")
                    for j, hist_msg in enumerate(simple_data['history'][:3], 1):
                        print(f"     {j}. {hist_msg[:65]}...")
                    if len(simple_data['history']) > 3:
                        print(f"     ... è¿˜æœ‰ {len(simple_data['history']) - 3} æ¡")
                else:
                    print(f"   history:   []")
                
                print("   " + "-" * 76)
                
                # JSONæ ¼å¼é¢„è§ˆ
                if i <= 3:  # åªå±•ç¤ºå‰3æ¡çš„å®Œæ•´JSON
                    print(f"\n   ğŸ“‹ JSONæ ¼å¼:")
                    json_str = json.dumps(simple_data, ensure_ascii=False, indent=4)
                    for line in json_str.split('\n'):
                        print(f"   {line}")
                
                print("-" * 80)
            
            if len(raw_groups) > 200:
                print(f"\n... è¿˜æœ‰ {len(raw_groups) - 200} æ¡æ¶ˆæ¯æœªæ˜¾ç¤º")
            
            # ç»Ÿè®¡ä¿¡æ¯ - å¢å¼ºç‰ˆ
            print("\n" + "=" * 80)
            print("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼ˆåŸºäºæ–°æ ¼å¼ï¼‰")
            print("=" * 80)
            print(f"åŸå§‹æ¶ˆæ¯æ•°: {len(raw_groups)}")
            print(f"äº¤æ˜“ç»„æ•°: {len(trade_groups)}")
            
            # ç»Ÿè®¡æœ‰ä½œè€…çš„æ¶ˆæ¯
            with_author = sum(1 for g in raw_groups if g.author)
            print(f"æœ‰ä½œè€…ä¿¡æ¯: {with_author} ({with_author/len(raw_groups)*100:.1f}%)")
            
            # ç»Ÿè®¡æœ‰æ—¶é—´æˆ³çš„æ¶ˆæ¯
            with_timestamp = sum(1 for g in raw_groups if g.timestamp)
            print(f"æœ‰æ—¶é—´æˆ³: {with_timestamp} ({with_timestamp/len(raw_groups)*100:.1f}%)")
            
            # ç»Ÿè®¡æœ‰å¼•ç”¨çš„æ¶ˆæ¯
            with_quote = sum(1 for g in raw_groups if g.quoted_context)
            print(f"æœ‰å¼•ç”¨å†…å®¹: {with_quote} ({with_quote/len(raw_groups)*100:.1f}%)")
            
            # ç»Ÿè®¡æ¶ˆæ¯ä½ç½®åˆ†å¸ƒ
            position_stats = {}
            history_stats = {'with_history': 0, 'total_history_count': 0}
            
            for g in raw_groups:
                simple = g.to_simple_dict()
                pos = simple['position']
                position_stats[pos] = position_stats.get(pos, 0) + 1
                
                if simple['history']:
                    history_stats['with_history'] += 1
                    history_stats['total_history_count'] += len(simple['history'])
            
            print(f"\næ¶ˆæ¯ä½ç½®åˆ†å¸ƒ:")
            for pos, count in sorted(position_stats.items()):
                print(f"  {pos:8s}: {count:3d} ({count/len(raw_groups)*100:.1f}%)")
            
            print(f"\nhistoryå­—æ®µç»Ÿè®¡:")
            print(f"  æœ‰å†å²æ¶ˆæ¯: {history_stats['with_history']} ({history_stats['with_history']/len(raw_groups)*100:.1f}%)")
            if history_stats['with_history'] > 0:
                avg_history = history_stats['total_history_count'] / history_stats['with_history']
                print(f"  å¹³å‡å†å²æ¡æ•°: {avg_history:.1f}")
            
            print("=" * 80)
            
            # ç”Ÿæˆåˆ†ææŠ¥å‘Š
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_file = f"debug/message_analysis_{timestamp}.txt"
            
            print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜è¯¦ç»†æŠ¥å‘Š...")
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("=" * 80 + "\n")
                f.write("æœ¬åœ°HTMLæ¶ˆæ¯æå–åˆ†ææŠ¥å‘Š\n")
                f.write("=" * 80 + "\n\n")
                f.write(f"æºæ–‡ä»¶: {html_file}\n")
                f.write(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æ–‡ä»¶å¤§å°: {file_size:.2f} MB\n\n")
                
                f.write("=" * 80 + "\n")
                f.write("ç»Ÿè®¡ä¿¡æ¯\n")
                f.write("=" * 80 + "\n\n")
                f.write(f"åŸå§‹æ¶ˆæ¯æ•°: {len(raw_groups)}\n")
                f.write(f"äº¤æ˜“ç»„æ•°: {len(trade_groups)}\n")
                f.write(f"æœ‰ä½œè€…ä¿¡æ¯: {with_author} ({with_author/len(raw_groups)*100:.1f}%)\n")
                f.write(f"æœ‰æ—¶é—´æˆ³: {with_timestamp} ({with_timestamp/len(raw_groups)*100:.1f}%)\n")
                f.write(f"æœ‰å¼•ç”¨å†…å®¹: {with_quote} ({with_quote/len(raw_groups)*100:.1f}%)\n\n")
                
                # æ·»åŠ æ–°æ ¼å¼ç»Ÿè®¡
                position_stats = {}
                history_stats = {'with_history': 0, 'total_history_count': 0}
                
                for g in raw_groups:
                    simple = g.to_simple_dict()
                    pos = simple['position']
                    position_stats[pos] = position_stats.get(pos, 0) + 1
                    
                    if simple['history']:
                        history_stats['with_history'] += 1
                        history_stats['total_history_count'] += len(simple['history'])
                
                f.write("æ¶ˆæ¯ä½ç½®åˆ†å¸ƒ:\n")
                for pos, count in sorted(position_stats.items()):
                    f.write(f"  {pos:8s}: {count:3d} ({count/len(raw_groups)*100:.1f}%)\n")
                
                f.write(f"\nhistoryå­—æ®µç»Ÿè®¡:\n")
                f.write(f"  æœ‰å†å²æ¶ˆæ¯: {history_stats['with_history']} ({history_stats['with_history']/len(raw_groups)*100:.1f}%)\n")
                if history_stats['with_history'] > 0:
                    avg_history = history_stats['total_history_count'] / history_stats['with_history']
                    f.write(f"  å¹³å‡å†å²æ¡æ•°: {avg_history:.1f}\n")
                f.write("\n")
                
                f.write("=" * 80 + "\n")
                f.write("è¯¦ç»†è¡¨æ ¼è§†å›¾\n")
                f.write("=" * 80 + "\n\n")
                f.write(format_as_detailed_table(trade_groups))
                
                f.write("\n\n" + "=" * 80 + "\n")
                f.write("åˆ†ç»„æ‘˜è¦è§†å›¾\n")
                f.write("=" * 80 + "\n\n")
                f.write(format_as_table(trade_groups))
                
                f.write("\n\n" + "=" * 80 + "\n")
                f.write("æ‰€æœ‰åŸå§‹æ¶ˆæ¯ï¼ˆæ–°æ ¼å¼ï¼‰\n")
                f.write("=" * 80 + "\n\n")
                
                import json
                for i, group in enumerate(raw_groups, 1):
                    # ä½¿ç”¨æ–°çš„ç®€åŒ–æ ¼å¼
                    simple_data = group.to_simple_dict()
                    
                    f.write(f"\n{i}. æ¶ˆæ¯ #{i}\n")
                    f.write("-" * 80 + "\n")
                    f.write(f"domID:     {simple_data['domID']}\n")
                    f.write(f"position:  {simple_data['position']}\n")
                    f.write(f"timestamp: {simple_data['timestamp'] or '(æœªè¯†åˆ«)'}\n")
                    f.write(f"content:   {simple_data['content']}\n")
                    
                    if simple_data['refer']:
                        f.write(f"refer:     {simple_data['refer']}\n")
                    
                    if simple_data['history']:
                        f.write(f"history:   [{len(simple_data['history'])} æ¡å†å²æ¶ˆæ¯]\n")
                        for j, hist_msg in enumerate(simple_data['history'], 1):
                            f.write(f"  {j}. {hist_msg}\n")
                    else:
                        f.write(f"history:   []\n")
                    
                    # å®Œæ•´JSONæ ¼å¼
                    f.write(f"\nJSONæ ¼å¼:\n")
                    json_str = json.dumps(simple_data, ensure_ascii=False, indent=2)
                    for line in json_str.split('\n'):
                        f.write(f"  {line}\n")
                    
                    # æ—§æ ¼å¼ä¿¡æ¯ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
                    f.write(f"\næ—§æ ¼å¼å¯¹æ¯”:\n")
                    f.write(f"  ä½œè€…: {group.author or '(æœªè¯†åˆ«)'}\n")
                    if group.related_messages:
                        f.write(f"  å…³è”æ¶ˆæ¯æ•°: {len(group.related_messages)}\n")
                    full_content = group.get_full_content()
                    f.write(f"  å®Œæ•´å†…å®¹:\n")
                    for line in full_content.split('\n'):
                        f.write(f"    {line}\n")
                    
                    f.write("\n" + "-" * 80 + "\n")
            
            print(f"âœ… è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}\n")
            
            print("=" * 80)
            print("åˆ†æå®Œæˆï¼")
            print("=" * 80)
            print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
            print(f"   1. æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š: cat {report_file}")
            print("   2. å¦‚æœæå–ä¸å‡†ç¡®ï¼ŒæŸ¥çœ‹ doc/SELECTOR_OPTIMIZATION.md")
            print("   3. è°ƒæ•´é€‰æ‹©å™¨: vim scraper/message_extractor.py")
            print("   4. é‡æ–°è¿è¡Œæ­¤è„šæœ¬éªŒè¯")
            print("=" * 80 + "\n")
            
            # å…³é—­æµè§ˆå™¨
            await browser.close()
            
        except Exception as e:
            print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            if 'browser' in locals():
                await browser.close()


def select_html_file():
    """
    è®©ç”¨æˆ·é€‰æ‹©è¦åˆ†æçš„HTMLæ–‡ä»¶
    
    Returns:
        é€‰æ‹©çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå–æ¶ˆåˆ™è¿”å›None
    """
    # æŸ¥æ‰¾debugç›®å½•ä¸‹çš„HTMLæ–‡ä»¶
    html_files = glob("debug/page_*.html")
    
    if not html_files:
        print("âŒ æœªæ‰¾åˆ°HTMLæ–‡ä»¶")
        print("\nğŸ’¡ æç¤º: è¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤å¯¼å‡ºHTML:")
        print("   python3 main.py --test export-dom\n")
        return None
    
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
    html_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
    
    print(f"ğŸ“ æ‰¾åˆ° {len(html_files)} ä¸ªHTMLæ–‡ä»¶:\n")
    for i, file in enumerate(html_files[:10], 1):
        mtime = os.path.getmtime(file)
        time_str = datetime.fromtimestamp(mtime).strftime("%Y-%m-%d %H:%M:%S")
        size_mb = os.path.getsize(file) / 1024 / 1024
        print(f"   {i}. {os.path.basename(file)}")
        print(f"      æ—¶é—´: {time_str}, å¤§å°: {size_mb:.2f} MB")
    
    if len(html_files) > 10:
        print(f"\n   ... è¿˜æœ‰ {len(html_files) - 10} ä¸ªæ–‡ä»¶")
    
    # é€‰æ‹©æ–‡ä»¶
    print("\nè¯·é€‰æ‹©è¦åˆ†æçš„æ–‡ä»¶ (è¾“å…¥åºå·ï¼Œé»˜è®¤=1): ", end='')
    choice = input().strip()
    
    if not choice:
        choice = "1"
    
    try:
        index = int(choice) - 1
        if index < 0 or index >= len(html_files):
            print("âŒ æ— æ•ˆçš„é€‰æ‹©")
            return None
        return html_files[index]
    except ValueError:
        print("âŒ æ— æ•ˆçš„è¾“å…¥")
        return None


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 80)
    print("æœ¬åœ°HTMLæ¶ˆæ¯æå–åˆ†æå·¥å…·")
    print("=" * 80 + "\n")
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    export_json = True  # é»˜è®¤å¯¼å‡ºJSON
    html_file = None
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        for arg in sys.argv[1:]:
            if arg == '--no-json':
                export_json = False
            elif not arg.startswith('--'):
                html_file = arg
        
        if html_file and not os.path.exists(html_file):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {html_file}")
            print("\nä½¿ç”¨æ–¹æ³•:")
            print(f"   python3 {sys.argv[0]} [HTMLæ–‡ä»¶è·¯å¾„] [é€‰é¡¹]")
            print(f"   python3 {sys.argv[0]}  # äº¤äº’å¼é€‰æ‹©æ–‡ä»¶")
            print("\né€‰é¡¹:")
            print("   --no-json    ä¸å¯¼å‡ºJSONæ–‡ä»¶\n")
            return
    
    if not html_file:
        # äº¤äº’å¼é€‰æ‹©æ–‡ä»¶
        html_file = select_html_file()
        if not html_file:
            return
    
    # åˆ†ææ–‡ä»¶
    asyncio.run(analyze_html_messages(html_file, export_json=export_json))


if __name__ == "__main__":
    main()
